This 5-day course is part of [ESSLLI 2016](http://esslli2016.unibz.it/). It aims to introduce students to the use of corpora of naturally occurring language for research in semantics/pragmatics.

In order to make the course as useful as possible to the greatest number of participants, **please fill out [this survey](https://docs.google.com/forms/d/e/1FAIpQLSeEFAbBObNEkY4VoCX4Vbj4D-6NwhCMXoyN3GnVhe6Jv4srtg/viewform) by August 9**!

# Lecturer

[Judith Degen](https://sites.google.com/site/judithdegen/) -- *jdegen@stanford.edu*

# Course description

Traditionally, the primary source of data in pragmatics has been researchers’ intuitions about utterance meanings. However, the small numbers of introspective judgments about examples, hand-selected by researchers who themselves provide these judgments, introduces bias into the  phenomena under investigation.  The recently emerging use of experimental methods for probing linguistically untrained  language users’ interpretations has ameliorated the bias introduced by small numbers of judgments. It cannot, however, remove item bias: researchers  artificially construct the stimuli used in experiments. Fortunately, studying corpora of naturally occurring language can reduce item bias. Corpora provide naturally occurring utterances that can be used in tandem with platforms like Mechanical Turk to provide large-scale crowd-sourced interpretations of these utterances, thereby allowing for constructing large databases of different types of meanings (e.g., implicatures) in context. The course will introduce students to the use of corpora of naturally occurring language for research in semantics/pragmatics.

# Syllabus

When        | What               | Reading(s) / resources | Slides
---------- | ------------------ | ---------------------- | -------
Monday     | Introduction: utility of corpora for research in semantics/pragmatics; annotation; search; hands-on project intro (projection behavior of (non-/semi-)factive verbs)| [Potts & de Marneffe 2014](http://web.stanford.edu/~cgpotts/papers/demarneffe-potts-lingann.pdf); [Tonhauser et al 2013](readings/tonhauser2013.pdf) |
Tuesday | TGrep2 tutorial: search corpora for syntactic patterns based on regular expressions |  |
Wednesday | TDTlite tutorial: building an annotated database of naturally occurring scalar implicatures | [Degen 2015](/readings/degen2015.pdf) |
Thursday | Build a database of (non-/semi-)factive verbs | |
Friday | Discussion of results; reflection | |

# Resources

- [TGrep2](https://tedlab.mit.edu/~dr/Tgrep2/) and the [TGrep2 User Manual](https://tedlab.mit.edu/~dr/Tgrep2/tgrep2.pdf)
- [TDTlite](https://github.com/thegricean/TDTlite) on GitHub
- [TDTlite User Manual](https://github.com/thegricean/TDTlite/blob/master/docs/tdt_manual.pdf)
- Stefan Gries's book [Quantitative Corpus Linguistics with R](https://www.routledge.com/Quantitative-Corpus-Linguistics-with-R-A-Practical-Introduction-2nd-Edition/Gries/p/book/9781138816275)
- [Linguistic Data Consortium](https://www.ldc.upenn.edu/language-resources/data)