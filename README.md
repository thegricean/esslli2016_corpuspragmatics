# Corpus Methods for Research in Pragmatics

In order to make the course as useful as possible to the most people, please fill out this survey!

## Syllabus

### Day 1

- Why use corpora (in Linguistics generally, in Pragmatics in particular)?

- Types of questions one can and cannot answer using corpora

- Relation to other kinds of data (introspection, controlled psycholinguistic experiments in the lab and on the web)

- Overview of general corpus features:

	- size, genre, modality (spoken, written), accessibility

	- annotation: POS, syntax, reference, information status, prosody, social meta-information about speakers (e.g., gender, dialect, education level)

- Intro to class project domain: projection behavior of (non-/semi-)factive verbs


### Day 2

- TGrep2 tutorial -- saerch patterns based on regular expressions

	- search patterns used in Degen 2015

	- formulate search patterns to find interesting verbs and their contexts

### Day 3

- TDTlite tutorial -- building a database

	- walk through generating database used in Degen 2015

	- useful types of information to extract: lexical/syntactic context, word frequencies, ngram frequencies, word lengths, phonology, prosody, social information

	- extending/annotating the database with crowd-sourced pragmatic judgments

- R data analysis/visualization tutorial?

### Day 4

Build a preliminary database of verbs

### Day 5

Discussion, wrapup, issues, further directions, buffer


## Readings/resources

- de Marneffe & Potts
- Gelman & Hill
- Degen 2015
- Gries
- TDT User Manual
- TGrep2 tutorial